{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Greeks**\n",
    "\n",
    "9 May 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_forward_reverse_mode_identity(diff_u_list=[], u_bar_list=[], diff_A_list=[], A_bar_list = [],\n",
    "                                       diff_v_list =[], v_bar_list=[], diff_B_list=[], B_bar_list = []):\n",
    "    # diff_u_list, u_bar_list is a list of input np arrays\n",
    "    # diff_A_list, A_bar_list is a list of input nd arrays representing the input matrices \n",
    "    # diff_v_list, v_bar_list is a list of output np arrays\n",
    "    # diff_B_list, B_bar_list is a list of output nd arrays representing the output matrices \n",
    "    # to do: assert that the dimension of u_list and u_bar_list as well as A_list and A_bar_list is the same\n",
    "    sum_lhs = 0\n",
    "    for diff_u, u_bar in zip(diff_u_list, u_bar_list):\n",
    "        sum_lhs += np.dot(u_bar, diff_u)\n",
    "    for diff_A, A_bar in zip(diff_A_list, A_bar_list):\n",
    "        sum_lhs += np.trace(A_bar.transpose() @ diff_A)\n",
    "    sum_rhs = 0\n",
    "    for diff_v, v_bar in zip(diff_v_list, v_bar_list):\n",
    "        sum_rhs += np.dot(v_bar, diff_v)\n",
    "    for diff_B, B_bar in zip(diff_B_list, B_bar_list):\n",
    "        sum_rhs += np.trace(B_bar.transpose() @ diff_B)\n",
    "    #print(sum_lhs, sum_rhs)\n",
    "    err = abs(sum_lhs - sum_rhs)\n",
    "    \n",
    "    return err < 10e-15, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symmetric(A, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(A, A.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cholesky decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "d = 5\n",
    "A = np.identity(d)\n",
    "#corr = 1\n",
    "for i in range(d):\n",
    "    for j in range(i):\n",
    "        #corr -= 0.04\n",
    "        A[i][j] = 0.1\n",
    "        A[j][i] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input matrix is symmetric:  True\n"
     ]
    }
   ],
   "source": [
    "# check symmetry \n",
    "print(\"The input matrix is symmetric: \", check_symmetric(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "def cholesky_decomposition(A, complexA = False):\n",
    "    if complexA == True:\n",
    "        A_copy = A.astype(dtype=complex)\n",
    "        L = np.zeros((d,d), dtype=complex)\n",
    "    else:\n",
    "        A_copy = np.ndarray.copy(A)\n",
    "        L = np.zeros((d,d))\n",
    "    for i in range(d):\n",
    "        for j in range(i+1):\n",
    "            for k in range(j):\n",
    "                A_copy[i][j] = A_copy[i][j] - L[i][k]*L[j][k]\n",
    "            if j == i:\n",
    "                L[i][i] = np.sqrt(A_copy[i][i])\n",
    "            else:\n",
    "                L[i][j] = A_copy[i][j]/L[j][j]\n",
    "    assert(np.allclose(A, np.dot(L, L.transpose()), rtol = 10e-15, atol =10e-15)), \"L*L^T != A\"\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cholesky factorisation is correct:  True\n"
     ]
    }
   ],
   "source": [
    "# check Cholesky factorisation\n",
    "L_true = cholesky_decomposition(A)\n",
    "L_estimated = np.linalg.cholesky(A)\n",
    "\n",
    "print(\"The Cholesky factorisation is correct: \", np.allclose(L_true, L_estimated, rtol = 10e-15, atol = 10e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward mode \n",
    "def cholesky_decomposition_forward(A, diff_A):\n",
    "    # to do: check that A is symmetric, A and and has exactly two values being 1 (all the other being 0)\n",
    "    # to do: check A and diff_A have the same dimensions\n",
    "    A_copy = np.ndarray.copy(A)\n",
    "    diff_A_copy = np.ndarray.copy(diff_A)\n",
    "    L = np.zeros((d,d))\n",
    "    diff_L = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(i+1):\n",
    "            for k in range(j):\n",
    "                diff_A_copy[i][j] = diff_A_copy[i][j] - diff_L[i][k]*L[j][k] - L[i][k]*diff_L[j][k]\n",
    "                A_copy[i][j] = A_copy[i][j] - L[i][k]*L[j][k]\n",
    "            if j == i:\n",
    "                #diff_L[i][i] = 0.5 * diff_A_copy[i][i] / np.sqrt(A_copy[i][i])\n",
    "                #L[i][i] = np.sqrt(A_copy[i][i])\n",
    "                L[i][i] = np.sqrt(A_copy[i][i])\n",
    "                diff_L[i][i] = 0.5 * diff_A_copy[i][i] / L[i][i]\n",
    "            else:\n",
    "                diff_L[i][j] = diff_A_copy[i][j] / L[j][j] - (A_copy[i][j] * diff_L[j][j]) / L[j][j]**2\n",
    "                L[i][j] = A_copy[i][j] / L[j][j]\n",
    "    assert(np.allclose(A, np.dot(L, L.transpose()), rtol = 10e-15, atol =10e-15)), \"L*L^T != A\"\n",
    "\n",
    "    return L, diff_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse mode\n",
    "# note: no need of cholesky_decomposition_f, since we do not need intermediate values for the reverse mode of Cholesky decomposition\n",
    "def cholesky_decomposition_b(L, L_bar):\n",
    "    A_bar = np.zeros((d,d))\n",
    "    L_bar_copy = np.ndarray.copy(L_bar)\n",
    "    for i in reversed(range(d)):\n",
    "        for j in reversed(range(i+1)):\n",
    "            if i == j:\n",
    "                A_bar[i][i] = 0.5*L_bar_copy[i][i]/L[i][i]\n",
    "            else:\n",
    "                A_bar[i][j] = L_bar_copy[i][j]/L[j][j]\n",
    "                L_bar_copy[j][j] = L_bar_copy[j][j] - L_bar_copy[i][j] * L[i][j] / L[j][j]\n",
    "            for k in reversed(range(j)):\n",
    "                L_bar_copy[i][k] = L_bar_copy[i][k] - A_bar[i][j] * L[j][k]\n",
    "                L_bar_copy[j][k] = L_bar_copy[j][k] - A_bar[i][j] * L[i][k]\n",
    "    return A_bar\n",
    "\n",
    "def cholesky_decomposition_reverse(A, L_bar):\n",
    "    # forward pass \n",
    "    L =  cholesky_decomposition(A)\n",
    "    # backward pass \n",
    "    A_bar = cholesky_decomposition_b(L, L_bar)\n",
    "    return L, A_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Validation of sensitivities\n",
    "consider sensitivity of the correlation of stock s1 and stock s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameter\n",
    "s1 = 1 # smaller than s2\n",
    "s2 = 2\n",
    "assert(s1 < s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bumping\n",
    "epsilon = 10e-6\n",
    "\n",
    "A_minus = np.ndarray.copy(A)\n",
    "A_minus[s2][s1] -= epsilon\n",
    "A_minus[s1][s2] -= epsilon\n",
    "A_plus = np.ndarray.copy(A)\n",
    "A_plus[s2][s1] += epsilon \n",
    "A_plus[s1][s2] += epsilon\n",
    "s1_s2_corr_sensivity_bumping = (cholesky_decomposition(A_plus) - cholesky_decomposition(A_minus)) / (2*epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the difference between the sensivity approximation of corr_s1_s2 using bumping and the complex \n",
      "variable trick is 1.014787152056842e-11\n"
     ]
    }
   ],
   "source": [
    "# complex variable trick\n",
    "epsilon = 10e-20\n",
    "        \n",
    "A_epsilon = A.astype(complex)\n",
    "A_epsilon[s2][s1] += epsilon * 1j\n",
    "#A_epsilon[s1][s2] += epsilon * 1j\n",
    "            \n",
    "s1_s2_corr_sensitivity_complex_trick = (cholesky_decomposition(A_epsilon, complexA=True)).imag / epsilon\n",
    "print(\"\"\"the difference between the sensivity approximation of corr_s1_s2 using bumping and the complex \n",
    "variable trick is\"\"\", np.linalg.norm(s1_s2_corr_sensivity_bumping - s1_s2_corr_sensitivity_complex_trick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference of forward mode to the complex variable trick is:  1.9873754096201566e-17\n"
     ]
    }
   ],
   "source": [
    "# check forward mode\n",
    "diff_A = np.zeros((d, d))\n",
    "diff_A[s2][s1] = 1\n",
    "# diff_A[s1][s2] = 1\n",
    "L, diff_L  = cholesky_decomposition_forward(A, diff_A)\n",
    "print(\"\"\"Difference of forward mode to the complex variable trick is: \"\"\",\n",
    "        np.linalg.norm(diff_L - s1_s2_corr_sensitivity_complex_trick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The forward/ reverse mode identity holds:  True\n"
     ]
    }
   ],
   "source": [
    "# check reverse mode\n",
    "diff_A = np.tril(np.random.rand(d,d)) # since A is symmetric, the cholesky decomposition defines a mapping from\n",
    "                                      # the lower-triangular part of A to L. \n",
    "                                      # Thus, diff_A is lower triangular matrix.\n",
    "L_bar = np.random.rand(d, d)*2 - 1 # uniform samples in [-1, 1]\n",
    "\n",
    "L, diff_L = cholesky_decomposition_forward(A, diff_A)\n",
    "L, A_bar = cholesky_decomposition_reverse(A, L_bar)\n",
    "\n",
    "b, err = check_forward_reverse_mode_identity([], [] ,[diff_A], [A_bar], [], [], [diff_L], [L_bar])\n",
    "print(\"The forward/ reverse mode identity holds: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function check_forward_reverse_mode_identity is correct:  True\n"
     ]
    }
   ],
   "source": [
    "# check the function that checks the standard forward / reverse mode identity\n",
    "sum1 = 0\n",
    "sum2 = 0\n",
    "for i in range(d):\n",
    "    for j in range(i+1):\n",
    "        sum1 += A_bar[i][j] * diff_A[i][j]\n",
    "        sum2 += L_bar[i][j] * diff_L[i][j]\n",
    "err_true = abs(sum1 - sum2)/2\n",
    "print('The function check_forward_reverse_mode_identity is correct: ', abs(err_true - err) < 10e-16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM\n",
    "The payoff function is given by \n",
    "$$ P(s) = \\sum_{i=1}^d S_i. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "S0 = np.ones(d) # initial value\n",
    "r = 0.05\n",
    "N = 10 # number of time steps\n",
    "M = 100 # number of path simulations\n",
    "T = 1\n",
    "h = T/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "def gbm_path_simulation(L, L_complex = False):\n",
    "    if L_complex:\n",
    "        S = S0.astype(dtype=complex)\n",
    "    else:\n",
    "        S = np.ndarray.copy(S0)\n",
    "    for n in range(N):\n",
    "        Z_n = np.random.normal(size = d)\n",
    "        Z = np.dot(L, Z_n)\n",
    "        for i in range(d):\n",
    "            S[i] = S[i] * (1 + r*h + np.sqrt(h)*Z[i])\n",
    "    return S\n",
    "\n",
    "def gbm_path_simulation_f(L):\n",
    "    Z_list = []\n",
    "    Z_n_list = []\n",
    "    S_list = [S0]\n",
    "    S = np.ndarray.copy(S0)\n",
    "    for n in range(N):\n",
    "        Z_n = np.random.normal(size = d)\n",
    "        Z = np.dot(L, Z_n)\n",
    "        for i in range(d):\n",
    "            S[i] = S[i] * (1 + r*h + np.sqrt(h)*Z[i])\n",
    "        Z_list.append(Z), Z_n_list.append(Z_n), S_list.append(np.copy(S)) # do not forget copy here, otherwise \n",
    "                                                                          # the list will have the same value\n",
    "    return S_list, Z_n_list, Z_list\n",
    "\n",
    "def avg_payoff(L, payoff_fct = sum, L_complex = False):\n",
    "    avg = 0\n",
    "    for m in range(M):\n",
    "        S = gbm_path_simulation(L, L_complex)\n",
    "        payoff = payoff_fct(S)\n",
    "        avg += payoff\n",
    "    avg /= M\n",
    "    # to do: discounting\n",
    "    return avg\n",
    "\n",
    "# Used for the full AD approach\n",
    "def avg_payoff_f(L, M, payoff_fct = sum):\n",
    "    S_all_list = []\n",
    "    Z_n_all_list = []\n",
    "    Z_all_list = []\n",
    "    avg = 0\n",
    "    for m in range(M):\n",
    "        S_list, Z_n_list, Z_list = gbm_path_simulation_f(L)\n",
    "        S_all_list.append(S_list), Z_n_all_list.append(Z_n_list), Z_all_list.append(Z_list)\n",
    "        payoff = payoff_fct(S)\n",
    "        avg += payoff\n",
    "    avg /= M\n",
    "    return S_all_list, Z_n_all_list, Z_all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward mode \n",
    "def gbm_path_simulation_forward(L, diff_L):\n",
    "    S = np.ndarray.copy(S0)\n",
    "    diff_S = np.zeros(d)\n",
    "    for n in range(N):\n",
    "        Z_n = np.random.normal(size = d)\n",
    "        diff_Z = np.dot(diff_L, Z_n)\n",
    "        Z = np.dot(L, Z_n)\n",
    "        for i in range(d):\n",
    "            diff_S[i] = diff_S[i] * (1 + r*h + np.sqrt(h)*Z[i]) + S[i] * np.sqrt(h) * diff_Z[i]\n",
    "            S[i] = S[i] * (1 + r*h + np.sqrt(h)*Z[i])\n",
    "    return S, diff_S\n",
    "\n",
    "def avg_payoff_forward(L, diff_L, payoff_fct = sum, diff_payoff_fct = sum):  \n",
    "    diff_avg = 0 \n",
    "    avg = 0\n",
    "    for m in range(M):\n",
    "        S , diff_S = gbm_path_simulation_forward(L, diff_L)\n",
    "        diff_payoff = diff_payoff_fct(diff_S)\n",
    "        payoff = payoff_fct(S)\n",
    "        diff_avg += diff_payoff\n",
    "        avg += payoff\n",
    "    diff_avg /= M\n",
    "    avg /= M\n",
    "    return avg, diff_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse mode\n",
    "def gbm_path_simulation_b(S_list, Z_n_list, Z_list, S_bar):\n",
    "    S_bar_copy = np.copy(S_bar)\n",
    "    Z_bar = np.zeros(d)\n",
    "    L_bar = np.zeros(d)\n",
    "    for n in reversed(range(N)):\n",
    "        S = S_list[n]\n",
    "        Z_n = Z_n_list[n]\n",
    "        Z = Z_list[n]\n",
    "        for i in reversed(range(d)):\n",
    "            Z_bar[i] =  S[i]*np.sqrt(h) * S_bar_copy[i]\n",
    "            S_bar_copy[i] = (1 + r*h + np.sqrt(h)*Z[i]) * S_bar_copy[i]\n",
    "        L_bar = L_bar + np.outer(Z_bar, Z_n) # computes multiplication of dx1 and 1xd vector to obtain dxd matrix\n",
    "    return L_bar \n",
    "            \n",
    "def gbm_path_simulation_reverse(L, S_bar):\n",
    "    # forward pass\n",
    "    S_list, Z_n_list, Z_list = gbm_path_simulation_f(L)\n",
    "    # backward pass\n",
    "    L_bar = gbm_path_simulation_b(S_list, Z_n_list, Z_list, S_bar)\n",
    "    return L_bar\n",
    "\n",
    "def avg_payoff_reverse(L, M, avg_bar):\n",
    "    L_bar = np.zeros((d,d))\n",
    "    avg_bar /= M \n",
    "    for m in range(M):\n",
    "        S_bar = np.ones(d) * avg_bar \n",
    "        L_bar_path = gbm_path_simulation_reverse(L, S_bar) # do forward and reverse pass along one path\n",
    "        L_bar += L_bar_path\n",
    "    return L_bar\n",
    "\n",
    "# # random seed approach\n",
    "# def avg_payoff_reverse(L, M, avg_bar):\n",
    "#     L_bar = np.zeros((d,d))\n",
    "#     avg_bar /= M \n",
    "#     for m in range(M):\n",
    "#         rdm_state = np.random.get_state()\n",
    "#         for i in reversed(range(d)):\n",
    "#             np.random.set_state(rdm_state)\n",
    "#             S_bar = np.zeros(d)\n",
    "#             S_bar[i] += 1 # initilizes S_bar = e_i\n",
    "#             L_bar_path = gbm_path_simulation_reverse(L, S_bar) # do forward and reverse pass along one path\n",
    "#             L_bar += L_bar_path * avg_bar \n",
    "        \n",
    "#     return L_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse mode, pedantic approach with M simulations\n",
    "def avg_payoff_b(S_all_list, Z_n_all_list, Z_all_list, M, avg_bar):\n",
    "    L_bar = np.zeros(d)\n",
    "    avg_bar /= M\n",
    "    for m in reversed(range(M)):\n",
    "        Z_bar = np.zeros(d)\n",
    "        S_bar = np.ones(d)*avg_bar\n",
    "        for n in reversed(range(N)):\n",
    "            S = S_all_list[m][n]\n",
    "            Z_n = Z_n_all_list[m][n]\n",
    "            Z = Z_all_list[m][n]\n",
    "            for i in reversed(range(d)):\n",
    "                Z_bar[i] =  S[i]*np.sqrt(h) * S_bar[i]\n",
    "                S_bar[i] = (1 + r*h + np.sqrt(h)*Z[i]) * S_bar[i]\n",
    "            L_bar = L_bar + np.outer(Z_bar, Z_n)\n",
    "        #print(L_bar)\n",
    "    return L_bar \n",
    "\n",
    "\n",
    "def avg_payoff_reverse_pedantic(L, M, avg_bar):\n",
    "    # forward pass \n",
    "    S_all_list, Z_n_all_list, Z_all_list = avg_payoff_f(L, M)\n",
    "    # backward pass\n",
    "    L_bar = avg_payoff_b(S_all_list, Z_n_all_list, Z_all_list, M, avg_bar)\n",
    "    return L_bar\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of sensitivities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bumping \n",
    "epsilon = 10e-6\n",
    "\n",
    "np.random.seed(100)\n",
    "L_minus = np.ndarray.copy(L)\n",
    "L_minus[s2][s1] -= epsilon\n",
    "S_minus = gbm_path_simulation(L_minus)\n",
    "avg_minus = avg_payoff(L_minus)\n",
    "\n",
    "np.random.seed(100)\n",
    "L_plus = np.ndarray.copy(L)\n",
    "L_plus[s2][s1] += epsilon \n",
    "S_plus = gbm_path_simulation(L_plus)\n",
    "avg_plus = avg_payoff(L_plus)\n",
    "\n",
    "path_sensitivity_wrt_L_s1_s2_bumping = (S_plus - S_minus) / (2*epsilon)\n",
    "payoff_sensitivity_wrt_L_s1_s2_bumping = (avg_plus-avg_minus) / (2*epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path sensitivity: Difference between bumping and complex variable trick is  9.76518865769549e-12\n",
      "payoff sensitivity: Difference between bumping and complex variable trick is  3.472735779497249e-10\n"
     ]
    }
   ],
   "source": [
    "# complex variable trick\n",
    "epsilon = 10e-20\n",
    "        \n",
    "L_epsilon = L.astype(complex)\n",
    "L_epsilon[s2][s1] += epsilon * 1j\n",
    "            \n",
    "np.random.seed(100)\n",
    "path_sensitivity_wrt_L_s1_s2_complex_trick = gbm_path_simulation(L_epsilon, L_complex = True).imag / epsilon\n",
    "payoff_sensitivity_wrt_L_s1_s2_complex_trick = avg_payoff(L_epsilon, L_complex = True).imag / epsilon\n",
    "print(\"\"\"path sensitivity: Difference between bumping and complex variable trick is \"\"\", \n",
    "      np.linalg.norm(path_sensitivity_wrt_L_s1_s2_bumping - path_sensitivity_wrt_L_s1_s2_complex_trick))\n",
    "print(\"\"\"payoff sensitivity: Difference between bumping and complex variable trick is \"\"\", \n",
    "      np.linalg.norm(payoff_sensitivity_wrt_L_s1_s2_bumping - payoff_sensitivity_wrt_L_s1_s2_complex_trick))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path sensitivity: Difference between complex variable trick and forward mode 5.551115123125783e-17\n",
      "payoff sensitivity: Difference between complex variable trick and forward mode 1.3877787807814457e-17\n"
     ]
    }
   ],
   "source": [
    "# check forward mode \n",
    "np.random.seed(100)\n",
    "\n",
    "diff_L = np.zeros((d,d))\n",
    "diff_L[s2][s1] = 1\n",
    "S, diff_S = gbm_path_simulation_forward(L, diff_L)\n",
    "print(\"\"\"path sensitivity: Difference between complex variable trick and forward mode\"\"\", \n",
    "     np.linalg.norm(path_sensitivity_wrt_L_s1_s2_complex_trick - diff_S))\n",
    "avg, diff_avg = avg_payoff_forward(L, diff_L)\n",
    "print(\"\"\"payoff sensitivity: Difference between complex variable trick and forward mode\"\"\", \n",
    "     np.linalg.norm(payoff_sensitivity_wrt_L_s1_s2_complex_trick - diff_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The forward/ reverse mode identity for the path calculation holds:  True\n",
      "The forward/ reverse mode identity for the payoff calculation holds:  True\n"
     ]
    }
   ],
   "source": [
    "# check reverse mode\n",
    "S_bar = np.random.rand(d)\n",
    "#S_bar = np.ones(d)\n",
    "avg_bar = np.random.rand()\n",
    "#avg_bar = 1\n",
    "diff_L = np.random.rand(d, d)\n",
    "#diff_L = np.zeros((d,d))\n",
    "#diff_L[s2][s1] = 1\n",
    "\n",
    "\n",
    "np.random.seed(100)\n",
    "S, diff_S = gbm_path_simulation_forward(L, diff_L)\n",
    "avg, diff_avg = avg_payoff_forward(L, diff_L)\n",
    "\n",
    "np.random.seed(100)\n",
    "L_bar_path = gbm_path_simulation_reverse(L, S_bar)\n",
    "# L_bar_payoff_pedantic = avg_payoff_reverse_pedantic(L, M, avg_bar)\n",
    "L_bar_payoff = avg_payoff_reverse(L, M, avg_bar)\n",
    "\n",
    "b, err = check_forward_reverse_mode_identity([], [] ,[diff_L], [L_bar_path], [diff_S], [S_bar], [], [])\n",
    "print(\"The forward/ reverse mode identity for the path calculation holds: \", b)\n",
    "\n",
    "b, err = check_forward_reverse_mode_identity([], [] ,[diff_L], [L_bar_payoff], [diff_avg], [avg_bar], [], [])\n",
    "print(\"The forward/ reverse mode identity for the payoff calculation holds: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.8826357951812946 -2.8826357951812955\n",
      "0.0025319270849205816 0.0025319270849205864\n"
     ]
    }
   ],
   "source": [
    "# check that the function for the forward/ reverse mode identity holds\n",
    "lhs = np.trace(L_bar_path.transpose() @ diff_L)\n",
    "rhs = np.dot(diff_S, S_bar)\n",
    "print(lhs, rhs)\n",
    "\n",
    "lhs = np.trace(L_bar_payoff.transpose() @ diff_L)\n",
    "rhs = avg_bar * diff_avg\n",
    "print(lhs, rhs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow: Cholesky decomposition and GBM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "def correlation_greeks(A, complexA = False):\n",
    "    L = cholesky_decomposition(A, complexA)\n",
    "    avg = avg_payoff(L, L_complex = complexA)\n",
    "    return avg\n",
    "\n",
    "def correlation_greeks_f(A):\n",
    "    rdm_state = []\n",
    "    # rdm_state.append(np.random.get_state()) # not necessary here as Cholesky decomposition is not random\n",
    "    L = cholesky_decomposition(A)\n",
    "    rdm_state.append(np.random.get_state())\n",
    "    avg = avg_payoff(L)\n",
    "    return avg, L, rdm_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward mode\n",
    "def correlation_greeks_forward(A, diff_A):\n",
    "    L, diff_L = cholesky_decomposition_forward(A, diff_A)\n",
    "    agv, diff_avg = avg_payoff_forward(L, diff_L)\n",
    "    return avg, diff_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse mode\n",
    "\n",
    "# full Monte Carlo approach \n",
    "def correlation_greeks_b_MC(avg_bar, L, rdm_state):\n",
    "    np.random.set_state(rdm_state.pop())\n",
    "    A_bar_path_list = []\n",
    "    S_bar = np.ones(d) * avg_bar # given from the payoff\n",
    "    for m in range(M):\n",
    "        L_bar_path = gbm_path_simulation_reverse(L, S_bar) #checkpointing, since I have not saved relevant S, Z, Z_n in the forward step\n",
    "        A_bar_path = cholesky_decomposition_b(L, L_bar_path)\n",
    "        A_bar_path_list.append(A_bar_path)\n",
    "    \n",
    "    mean_A_bar = np.mean(A_bar_path_list, axis=0)\n",
    "    std_A_bar = np.std(A_bar_path_list, axis=0)\n",
    "    #print(\"MC:\")\n",
    "    #print(std_A_bar)\n",
    "    lower_bound = mean_A_bar-3*std_A_bar/np.sqrt(M)\n",
    "    upper_bound = mean_A_bar+3*std_A_bar/np.sqrt(M)\n",
    "    \n",
    "    return mean_A_bar, [lower_bound, upper_bound] \n",
    "\n",
    "def correlation_greeks_reverse_MC(A, avg_bar):\n",
    "    avg, L, rdm_state = correlation_greeks_f(A)\n",
    "    mean_A_bar, [lower_bound, upper_bound]  = correlation_greeks_b_MC(avg_bar, L, rdm_state)\n",
    "    return avg, (mean_A_bar, (lower_bound, upper_bound))\n",
    "\n",
    "# binning\n",
    "def correlation_greeks_b_binning(avg_bar, L, K, rdm_state):\n",
    "    np.random.set_state(rdm_state.pop())\n",
    "    nbr_paths_per_batch = int(M/K)\n",
    "    A_bar_list = []\n",
    "\n",
    "    for batch in range(K):\n",
    "        L_bar = avg_payoff_reverse(L, nbr_paths_per_batch, avg_bar) #checkpointing, since I have not saved relevant S, Z, Z_n in the forward step\n",
    "        A_bar = cholesky_decomposition_b(L, L_bar)\n",
    "        A_bar_list.append(A_bar)\n",
    "\n",
    "    mean_A_bar = np.mean(A_bar_list, axis=0)\n",
    "    std_A_bar = np.std(A_bar_list, axis=0)\n",
    "    #print(\"binning:\")\n",
    "    #print(std_A_bar)\n",
    "    lower_bound = mean_A_bar - 3*std_A_bar/np.sqrt(K)\n",
    "    upper_bound = mean_A_bar + 3*std_A_bar/np.sqrt(K)\n",
    "    \n",
    "    return mean_A_bar, [lower_bound, upper_bound]\n",
    "\n",
    "def correlation_greeks_reverse_binning(A, avg_bar, K):\n",
    "    avg, L, rdm_state = correlation_greeks_f(A)\n",
    "    mean_A_bar, [lower_bound, upper_bound]  = correlation_greeks_b_binning(avg_bar, L, K, rdm_state)\n",
    "    return avg, (mean_A_bar, (lower_bound, upper_bound))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complex variable trick\n",
    "epsilon = 10e-20\n",
    "        \n",
    "A_epsilon = A.astype(complex)\n",
    "A_epsilon[s2][s1] += epsilon * 1j\n",
    "            \n",
    "np.random.seed(100)\n",
    "payoff_sensitivity_wrt_s1_s2_complex_trick = correlation_greeks(A_epsilon, complexA=True).imag / epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payoff sensitivity: Difference between complex variable trick and forward mode 2.0816681711721685e-17\n"
     ]
    }
   ],
   "source": [
    "# check forward mode \n",
    "diff_A = np.zeros((d,d))\n",
    "diff_A[s2][s1] = 1\n",
    "\n",
    "np.random.seed(100)\n",
    "avg, diff_avg = correlation_greeks_forward(A, diff_A)\n",
    "print(\"\"\"payoff sensitivity: Difference between complex variable trick and forward mode\"\"\", \n",
    "     np.linalg.norm(payoff_sensitivity_wrt_s1_s2_complex_trick - diff_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The forward/ reverse mode identity for the standard AD calculation holds:  True\n",
      "The forward/ reverse mode identity for the Monte-Carlo approach holds:  True\n",
      "The forward/ reverse mode identity for the binning approach holds:  True\n"
     ]
    }
   ],
   "source": [
    "# check correlation greeks\n",
    "K = 20\n",
    "avg_bar = np.random.randn()\n",
    "#diff_A = np.tril(np.random.rand(d,d))\n",
    "diff_A = np.zeros((d,d))\n",
    "diff_A[s2][s1] = 1\n",
    "\n",
    "# forward mode \n",
    "np.random.seed(100)\n",
    "avg, diff_avg = correlation_greeks_forward(A, diff_A)\n",
    "\n",
    "# reverse mode\n",
    "\n",
    "# standard AD - no confidence interval for the sensitivity of the price\n",
    "np.random.seed(100)\n",
    "avg, L, rdm_state = correlation_greeks_f(A)\n",
    "np.random.set_state(rdm_state.pop())\n",
    "L_bar = avg_payoff_reverse(L, M, avg_bar) \n",
    "A_bar = cholesky_decomposition_b(L, L_bar)\n",
    "#print(A_bar)\n",
    "\n",
    "# Monte-Carlo approach\n",
    "np.random.seed(100)\n",
    "avg_MC, A_bar_MC = correlation_greeks_reverse_MC(A, avg_bar)\n",
    "#print(A_bar_MC[0])\n",
    "\n",
    "# binning\n",
    "np.random.seed(100)\n",
    "avg_binning, A_bar_binning = correlation_greeks_reverse_binning(A, avg_bar, K)\n",
    "#print(A_bar_binning[0])\n",
    "\n",
    "\n",
    "b, err = check_forward_reverse_mode_identity([], [], [diff_A], [A_bar], [diff_avg], [avg_bar], [], [])\n",
    "print(\"The forward/ reverse mode identity for the standard AD calculation holds: \", b)\n",
    "\n",
    "b, err = check_forward_reverse_mode_identity([], [], [diff_A], [A_bar_MC[0]], [diff_avg], [avg_bar], [], [])\n",
    "print(\"The forward/ reverse mode identity for the Monte-Carlo approach holds: \", b)\n",
    "\n",
    "b, err = check_forward_reverse_mode_identity([], [], [diff_A], [A_bar_binning[0]], [diff_avg], [avg_bar], [], [])\n",
    "print(\"The forward/ reverse mode identity for the binning approach holds: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of A_bar_MC is: \n",
      " [[ 0.03092689  0.          0.          0.          0.        ]\n",
      " [-0.05033404 -0.02860049  0.          0.          0.        ]\n",
      " [-0.02219425  0.04106514 -0.0234562   0.          0.        ]\n",
      " [-0.05697518  0.04981456 -0.01076241  0.02901437  0.        ]\n",
      " [-0.01804647  0.00519438 -0.03416544 -0.02312887 -0.01816489]]\n",
      "The 3 std confidence interval has lower bound: \n",
      " [[-0.04836703  0.          0.          0.          0.        ]\n",
      " [-0.19304388 -0.11664465  0.          0.          0.        ]\n",
      " [-0.16178027 -0.07737118 -0.10170026  0.          0.        ]\n",
      " [-0.21494928 -0.07593674 -0.14547342 -0.06452138  0.        ]\n",
      " [-0.15578116 -0.12501791 -0.1583495  -0.15715606 -0.10085796]]\n",
      "The 3 std confidence interval has upper bound: \n",
      " [[0.11022081 0.         0.         0.         0.        ]\n",
      " [0.09237581 0.05944367 0.         0.         0.        ]\n",
      " [0.11739177 0.15950147 0.05478786 0.         0.        ]\n",
      " [0.10099891 0.17556586 0.12394861 0.12255012 0.        ]\n",
      " [0.11968823 0.13540667 0.09001863 0.11089832 0.06452818]]\n",
      "----------------------------\n",
      "The mean of A_bar is: \n",
      " [[ 0.03092689  0.          0.          0.          0.        ]\n",
      " [-0.05033404 -0.02860049  0.          0.          0.        ]\n",
      " [-0.02219425  0.04106514 -0.0234562   0.          0.        ]\n",
      " [-0.05697518  0.04981456 -0.01076241  0.02901437  0.        ]\n",
      " [-0.01804647  0.00519438 -0.03416544 -0.02312887 -0.01816489]]\n",
      "The 3 std confidence interval has lower bound: \n",
      " [[-0.04220297  0.          0.          0.          0.        ]\n",
      " [-0.16578561 -0.11481739  0.          0.          0.        ]\n",
      " [-0.14692552 -0.09548941 -0.09809233  0.          0.        ]\n",
      " [-0.21056929 -0.04367356 -0.16238977 -0.08030495  0.        ]\n",
      " [-0.15678175 -0.10003797 -0.16569035 -0.1431624  -0.11586731]]\n",
      "The 3 std confidence interval has upper bound: \n",
      " [[0.10405675 0.         0.         0.         0.        ]\n",
      " [0.06511754 0.05761642 0.         0.         0.        ]\n",
      " [0.10253703 0.17761969 0.05117993 0.         0.        ]\n",
      " [0.09661892 0.14330268 0.14086496 0.13833369 0.        ]\n",
      " [0.12068882 0.11042673 0.09735948 0.09690466 0.07953754]]\n"
     ]
    }
   ],
   "source": [
    "print('The mean of A_bar_MC is: \\n', A_bar_MC[0])\n",
    "print(\"The 3 std confidence interval has lower bound: \\n\",A_bar_MC[1][0])\n",
    "print(\"The 3 std confidence interval has upper bound: \\n\", A_bar_MC[1][1])\n",
    "print(\"----------------------------\")\n",
    "print('The mean of A_bar is: \\n', A_bar_binning[0])\n",
    "print(\"The 3 std confidence interval has lower bound: \\n\",A_bar_binning[1][0])\n",
    "print(\"The 3 std confidence interval has upper bound: \\n\", A_bar_binning[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.146057493110082"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.04836703 / -0.04220297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5750386390045237"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.00228254 / 0.00088641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3214104830837798"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.00573989 / -0.00434376"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2517213508274032"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.00205972 / -0.00164551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0799401717649328"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.00559571 / 0.0051815"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unclear why the confidence interval should differ between the MC and the binning approach. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
